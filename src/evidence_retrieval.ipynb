{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the training, validation data, and evidence set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/train-claims.json')\n",
    "raw_train_data = json.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/dev-claims.json')\n",
    "raw_val_data = json.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/evidence.json')\n",
    "evidence_data = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the dataset\n",
    "for evidence_id, evidence in evidence_data.items():\n",
    "    evidence_data[evidence_id] = evidence.lower()\n",
    "\n",
    "def preprocess_data(raw_data, evidence_set):\n",
    "    # Map labels into numbers\n",
    "    label_map = {'SUPPORTS': 0, 'REFUTES': 1, 'NOT_ENOUGH_INFO': 2, 'DISPUTED': 3}\n",
    "    processed_data = []\n",
    "    for claim_id, claim_info in raw_data.items():\n",
    "        \n",
    "        # Lower all the words in both claim and evidences\n",
    "        claim_text = claim_info['claim_text'].lower()\n",
    "        evidences = [evidence_set[evidence_id] for evidence_id in claim_info['evidences'][:5]]  # Limit to max 5 evidence\n",
    "        evidences = \" [SEP] \".join(evidences)\n",
    "        label = label_map[claim_info['claim_label']]\n",
    "        processed_data.append((claim_text, evidences, label, claim_info['evidences']))\n",
    "    return processed_data\n",
    "\n",
    "# Load and preprocess your training and validation datasets\n",
    "train_data = preprocess_data(raw_train_data, evidence_data)\n",
    "val_data = preprocess_data(raw_val_data, evidence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/greysonchung/.cache/huggingface/hub/models--facebook--dpr-question_encoder-single-nq-base/snapshots/d04a52f6d2f96c60117a925e8c24c4043a75f265/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/greysonchung/.cache/huggingface/hub/models--facebook--dpr-question_encoder-single-nq-base/snapshots/d04a52f6d2f96c60117a925e8c24c4043a75f265/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/greysonchung/.cache/huggingface/hub/models--facebook--dpr-question_encoder-single-nq-base/snapshots/d04a52f6d2f96c60117a925e8c24c4043a75f265/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/greysonchung/.cache/huggingface/hub/models--facebook--dpr-question_encoder-single-nq-base/snapshots/d04a52f6d2f96c60117a925e8c24c4043a75f265/config.json\n",
      "Model config DPRConfig {\n",
      "  \"_name_or_path\": \"facebook/dpr-question_encoder-single-nq-base\",\n",
      "  \"architectures\": [\n",
      "    \"DPRQuestionEncoder\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"dpr\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"projection_dim\": 0,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/greysonchung/.cache/huggingface/hub/models--facebook--dpr-ctx_encoder-single-nq-base/snapshots/bb21a3c2b1656d60c6a8e920283bc40dabddadb8/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/greysonchung/.cache/huggingface/hub/models--facebook--dpr-ctx_encoder-single-nq-base/snapshots/bb21a3c2b1656d60c6a8e920283bc40dabddadb8/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/greysonchung/.cache/huggingface/hub/models--facebook--dpr-ctx_encoder-single-nq-base/snapshots/bb21a3c2b1656d60c6a8e920283bc40dabddadb8/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/greysonchung/.cache/huggingface/hub/models--facebook--dpr-ctx_encoder-single-nq-base/snapshots/bb21a3c2b1656d60c6a8e920283bc40dabddadb8/config.json\n",
      "Model config DPRConfig {\n",
      "  \"_name_or_path\": \"facebook/dpr-ctx_encoder-single-nq-base\",\n",
      "  \"architectures\": [\n",
      "    \"DPRContextEncoder\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"dpr\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"projection_dim\": 0,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# Initialise the tokenizers\n",
    "\n",
    "claim_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "evidence_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPRTrainDataset(Dataset):\n",
    "    def __init__(self, train_data, claim_max_len, evidence_max_len):\n",
    "        self.data = train_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        claims = self.data[index][0]\n",
    "        evidences = self.data[index][1]\n",
    "        evidence_ids = self.data[index][3]\n",
    "\n",
    "        return claims, evidences, evidence_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampling(claims, evidence_ids):\n",
    "    '''\n",
    "    This function performs negative sampling for a batch of claims\n",
    "    '''\n",
    "    batch_evidence_set = set([ids for ids in evidence_ids])\n",
    "    negative_evidences = []\n",
    "    \n",
    "    for i in range(len(claims)):\n",
    "        negative_candidates = batch_evidence_set - set(evidence_ids[i])\n",
    "        sample_size = len(evidence_ids[i])\n",
    "        sampled_ids = random.sample(negative_candidates, sample_size)\n",
    "\n",
    "        # Retrieve the actual evidence base on evidence ids\n",
    "        sampled_evidence = [evidence_data[evidence_id] for evidence_id in sampled_ids]\n",
    "        sampled_evidence = \" [SEP] \".join(sampled_evidence)\n",
    "        negative_evidences.append(sampled_evidence)\n",
    "\n",
    "    return negative_evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining collate function to process and combine samples from the dataset into a single batch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    claims, evidences, evidence_ids = zip(*batch)\n",
    "\n",
    "    negative_evidences = negative_sampling(claims, evidence_ids)\n",
    "    \n",
    "    # Tokenize the claim and evidence\n",
    "    claim_tokens = claim_tokenizer(claims, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    positive_evidence_tokens = evidence_tokenizer(evidences, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    negative_evidence_tokens = evidence_tokenizer(negative_evidences, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    return {\n",
    "        \"claim_inputs\": claim_tokens,\n",
    "        \"positive_evidence_inputs\": positive_evidence_tokens,\n",
    "        \"negative_evidence_inputs\": negative_evidence_tokens,\n",
    "    }    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
